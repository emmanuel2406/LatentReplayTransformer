{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with flores-200.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmanuelrassou/miniforge3-arm64/envs/avalanche-arm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flores_200 import Flores200, Flores200Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved up one directory: /Users/emmanuelrassou/Desktop/HarvardClasses/spring_2025/neuro_240/final_project\n",
      "Contents of directory: ['out.txt', '.myenv', '.DS_Store', 'requirements.txt', 'loss.txt', 'VAE_output_per_exp.png', 'images', 'dataset', 'fairseq', 'loss_curve_eng_fra.png', 'ar1-pytorch', 'training_demo.sh', 'modern_latent_replay', 'loss_01.txt', 'loss_02.txt', 'loss_curve_eng_afr__fra.png', 'model', 'Assignment 3_ Midterm Report.pdf', 'predictions.txt', 'miniforge.sh', 'Combatting Language Forgetting in MultiLingual Settings.pdf', '.vscode', 'avalanche_demo', 'small_100']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cd_home = os.getcwd() == '/Users/emmanuelrassou/Desktop/HarvardClasses/spring_2025/neuro_240/final_project'\n",
    "if not cd_home:\n",
    "    os.chdir(\"..\")  # Move one directory up\n",
    "    print(\"Moved up one directory:\", os.getcwd())  # Check current directory\n",
    "    print(\"Contents of directory:\", os.listdir())  # Equivalent to `%ls`\n",
    "\n",
    "cd_home = True  # Update flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Avalanche Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "\n",
    "class FloresDataset(Dataset):\n",
    "    def __init__(self, data_dir, src_lang, tgt_lang, suffix):\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        # self.task_labels = []\n",
    "        src_file_path = os.path.join(data_dir, suffix,  f\"{src_lang}.{suffix}\")\n",
    "        tgt_file_path = os.path.join(data_dir, suffix,  f\"{tgt_lang}.{suffix}\")\n",
    "\n",
    "        if not os.path.exists(src_file_path):\n",
    "            raise FileNotFoundError(f\"Source file {src_file_path} does not exist.\")\n",
    "        if not os.path.exists(tgt_file_path):\n",
    "            raise FileNotFoundError(f\"Target file {tgt_file_path} does not exist.\")\n",
    "\n",
    "        with open(src_file_path, \"r\", encoding=\"utf-8\") as src_file, \\\n",
    "             open(tgt_file_path, \"r\", encoding=\"utf-8\") as tgt_file:\n",
    "            src_sentences = src_file.readlines()\n",
    "            tgt_sentences = tgt_file.readlines()\n",
    "\n",
    "            if len(src_sentences) != len(tgt_sentences):\n",
    "                raise ValueError(\"Source and target files must have the same number of lines.\")\n",
    "\n",
    "            self.data.extend(src_sentences)\n",
    "            self.targets.extend(tgt_sentences)\n",
    "            # self.task_labels.extend([src_lang] * len(src_sentences))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].strip(), self.targets[idx].strip()#, self.task_labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Pytorch dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from small_100.tokenization_small100 import SMALL100Tokenizer\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\" Custom collate function to pad variable-length sequences. \"\"\"\n",
    "    src_texts, tgt_texts = zip(*batch)  # Unzip source and target sequences\n",
    "    \n",
    "    # Tokenize if needed (replace with actual tokenizer)\n",
    "    tokenizer = SMALL100Tokenizer()\n",
    "    tokenizer.src_lang = \"en\"\n",
    "    tokenizer.tgt_lang = \"fr\"\n",
    "    src_tokens = [tokenizer(text, return_tensors=\"pt\") for text in src_texts]\n",
    "    tgt_tokens = [tokenizer(text, return_tensors=\"pt\") for text in tgt_texts]\n",
    "\n",
    "    return src_tokens, tgt_tokens\n",
    "\n",
    "    #Pad sequences to match the longest one in the batch\n",
    "    # src_padded = pad_sequence(src_tokens, batch_first=True, padding_value=\"\")\n",
    "    # tgt_padded = pad_sequence(tgt_tokens, batch_first=True, padding_value=\"\")\n",
    "\n",
    "    # return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the directory containing your .dev files and the languages of interest\n",
    "data_directory = os.path.join(\"dataset\", \"flores200_dataset\")\n",
    "train_suffix = \"dev\"\n",
    "test_suffix = \"devtest\"\n",
    "\n",
    "src_languages = [\"eng_Latn\", \"fra_Latn\", \"afr_Latn\"]  # Example source languages\n",
    "tgt_language = \"cjk_Latn\"\n",
    "\n",
    "# Create Pytorch data loaders\n",
    "\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "\n",
    "for task_id, src_lang in enumerate(src_languages):\n",
    "    train_flores = FloresDataset(data_directory, src_lang, tgt_language, train_suffix)\n",
    "    train_loader = DataLoader(train_flores, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "    train_loaders.append(train_loader)\n",
    "\n",
    "    # Assuming test datasets are structured similarly\n",
    "    test_flores = FloresDataset(data_directory, src_lang, tgt_language, test_suffix)\n",
    "    test_loader = DataLoader(test_flores, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loaders.append(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0:\n",
      "Source batch shape: 16\n",
      "Target batch shape: 16\n",
      "Task 1:\n",
      "Source batch shape: 16\n",
      "Target batch shape: 16\n",
      "Task 2:\n",
      "Source batch shape: 16\n",
      "Target batch shape: 16\n",
      "Task 0:\n",
      "Source batch shape: 16\n",
      "Target batch shape: 16\n",
      "Task 1:\n",
      "Source batch shape: 16\n",
      "Target batch shape: 16\n",
      "Task 2:\n",
      "Source batch shape: 16\n",
      "Target batch shape: 16\n"
     ]
    }
   ],
   "source": [
    "# explore train loader\n",
    "for task_id, train_loader in enumerate(train_loaders):\n",
    "    print(f\"Task {task_id}:\")\n",
    "    for batch in train_loader:\n",
    "        src_batch, tgt_batch = batch\n",
    "        print(f\"Source batch shape: {len(src_batch)}\")\n",
    "        print(f\"Target batch shape: {len(tgt_batch)}\")\n",
    "        break\n",
    "\n",
    "# explore test loader\n",
    "for task_id, test_loader in enumerate(test_loaders):\n",
    "    print(f\"Task {task_id}:\")\n",
    "    for batch in test_loader:\n",
    "        src_batch, tgt_batch = batch\n",
    "        print(f\"Source batch shape: {len(src_batch)}\")\n",
    "        print(f\"Target batch shape: {len(tgt_batch)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark created successfully!\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks import benchmark_from_datasets\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "\n",
    "train_datasets = [AvalancheDataset(train_loader.dataset) for train_loader in train_loaders]\n",
    "test_datasets = [AvalancheDataset(test_loader.dataset) for test_loader in test_loaders]\n",
    "\n",
    "scenario = benchmark_from_datasets(train=train_datasets, test=test_datasets)\n",
    "print(\"Benchmark created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avalanche-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
